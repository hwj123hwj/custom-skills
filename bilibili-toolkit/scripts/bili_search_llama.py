# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "llama-index",
#     "llama-index-vector-stores-postgres",
#     "llama-index-llms-openai-like",
#     "llama-index-embeddings-openai",
#     "python-dotenv",
#     "SQLAlchemy",
#     "psycopg[binary]",
#     "httpx",
#     "nest_asyncio",
#     "rich",
# ]
# ///

import os
import sys
import asyncio
import httpx
import nest_asyncio
import logging
import io
from typing import List, Optional, Any
from dotenv import load_dotenv
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.markdown import Markdown

# 1. å½»åº•å±è”½å™ªéŸ³ï¼šç¦æ­¢åº“æ—¥å¿—å’Œè­¦å‘Š
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3" # å±è”½ TensorFlow è­¦å‘Š
logging.getLogger("llama_index").setLevel(logging.ERROR)

console = Console()

# 2. åŸºç¡€é…ç½®
nest_asyncio.apply()
logging.getLogger("llama_index").setLevel(logging.ERROR)

from llama_index.core import StorageContext, VectorStoreIndex, Settings
from llama_index.core.embeddings import BaseEmbedding
from llama_index.core.postprocessor.types import BaseNodePostprocessor
from llama_index.core.schema import NodeWithScore, QueryBundle
from llama_index.core.vector_stores.types import VectorStoreQueryMode
from llama_index.core.vector_stores import MetadataFilters, ExactMatchFilter
from llama_index.core.response_synthesizers import ResponseMode
from llama_index.vector_stores.postgres import PGVectorStore
from llama_index.llms.openai_like import OpenAILike

load_dotenv()

# ================= è‡ªå®šä¹‰ OpenAI å…¼å®¹ Embedding ç±» =================
class SiliconFlowEmbedding(BaseEmbedding):
    api_key: str = ""
    api_base: str = ""

    def __init__(
        self, 
        model_name: str = "BAAI/bge-m3", 
        api_key: str = "", 
        api_base: str = "", 
        **kwargs
    ):
        super().__init__(
            model_name=model_name, 
            api_key=api_key, 
            api_base=api_base, 
            **kwargs
        )

    @classmethod
    def class_name(cls) -> str:
        return "SiliconFlowEmbedding"

    def _get_query_embedding(self, query: str) -> List[float]:
        return asyncio.run(self._aget_query_embedding(query))

    def _get_text_embedding(self, text: str) -> List[float]:
        return asyncio.run(self._aget_text_embedding(text))

    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:
        return asyncio.run(self._aget_text_embeddings(texts))

    async def _aget_query_embedding(self, query: str) -> List[float]:
        embeddings = await self._aget_text_embeddings([query])
        return embeddings[0]

    async def _aget_text_embedding(self, text: str) -> List[float]:
        embeddings = await self._aget_text_embeddings([text])
        return embeddings[0]

    async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:
        # æ‰‹åŠ¨é™åˆ¶æ¯æ‰¹å¤§å°ï¼Œé˜²æ­¢ API æŠ¥ 413 é”™è¯¯
        max_batch = 4
        all_embeddings = []
        
        url = f"{self.api_base}/embeddings"
        headers = {"Authorization": f"Bearer {self.api_key}"}
        
        async with httpx.AsyncClient() as client:
            for i in range(0, len(texts), max_batch):
                batch_text = texts[i:i+max_batch]
                payload = {"model": self.model_name, "input": batch_text}
                
                response = await client.post(url, json=payload, headers=headers, timeout=60)
                if response.status_code == 413:
                    # è¿›ä¸€æ­¥æ‹†åˆ†
                    for single_text in batch_text:
                        r = await client.post(url, json={"model": self.model_name, "input": [single_text]}, headers=headers)
                        r.raise_for_status()
                        all_embeddings.append(r.json()["data"][0]["embedding"])
                else:
                    response.raise_for_status()
                    data = response.json()
                    all_embeddings.extend([item["embedding"] for item in data["data"]])
                    
        return all_embeddings

# ================= è‡ªå®šä¹‰ SiliconFlow Reranker ç±» =================
class SiliconFlowRerank(BaseNodePostprocessor):
    """ä½¿ç”¨ç¡…åŸºæµåŠ¨ API è¿›é€»è¾‘é‡æ’"""
    model: str
    api_key: str
    top_n: int = 3

    def __init__(self, model: str, api_key: str, top_n: int = 3):
        super().__init__(model=model, api_key=api_key, top_n=top_n)

    @classmethod
    def class_name(cls) -> str:
        return "SiliconFlowRerank"

    def _postprocess_nodes(
        self,
        nodes: List[NodeWithScore],
        query_bundle: Optional[QueryBundle] = None,
    ) -> List[NodeWithScore]:
        if query_bundle is None or not nodes:
            return nodes

        url = "https://api.siliconflow.cn/v1/rerank"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        texts = [node.node.get_content() for node in nodes]
        payload = {
            "model": self.model,
            "query": query_bundle.query_str,
            "documents": texts,
            "top_n": self.top_n
        }

        with httpx.Client() as client:
            response = client.post(url, json=payload, headers=headers, timeout=60)
            response.raise_for_status()
            results = response.json()

        new_nodes = []
        # SiliconFlow è¿”å›çš„ results['results'] åŒ…å«äº† index å’Œ relevance_score
        for res in results.get("results", []):
            idx = res["index"]
            original_node = nodes[idx]
            original_node.score = res["relevance_score"] # æ›´æ–°ä¸ºé‡æ’åçš„åˆ†æ•°
            new_nodes.append(original_node)

        return new_nodes

# ================= é…ç½®åŒº =================
# ================= é…ç½®åŠ è½½ =================
def load_secrets():
    """é€’å½’å‘ä¸ŠæŸ¥æ‰¾ secrets.json"""
    import json
    current_dir = os.path.dirname(os.path.abspath(__file__))
    while True:
        secrets_path = os.path.join(current_dir, "secrets.json")
        if os.path.exists(secrets_path):
            try:
                with open(secrets_path, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception:
                return {}
        
        parent_dir = os.path.dirname(current_dir)
        if parent_dir == current_dir:  # åˆ°è¾¾æ ¹ç›®å½•
            return {}
        current_dir = parent_dir

SECRETS = load_secrets()

# ================= ç¯å¢ƒå˜é‡å¢å¼ºåŠ è½½ =================
def get_env_flexible(key_name, default=None):
    """ä¼˜å…ˆä» os.getenv è·å–ï¼Œå¦‚æœä¸ºç©ºåˆ™ Windows æ³¨å†Œè¡¨è¯»å–ï¼Œæœ€å secrets.json"""
    val = os.getenv(key_name)
    if val: return val
    
    if sys.platform == "win32":
        try:
            import winreg
            with winreg.OpenKey(winreg.HKEY_CURRENT_USER, r"Environment") as key:
                val, _ = winreg.QueryValueEx(key, key_name)
                if val: return val
        except Exception:
            pass
            
    if SECRETS and key_name in SECRETS:
        return SECRETS[key_name]
    return default

# AI é…ç½®ä»ç¯å¢ƒå˜é‡åŠ è½½ï¼Œsecrets.json ä½œä¸ºå¤‡ç”¨
SILICONFLOW_API_KEY = get_env_flexible("SILICONFLOW_API_KEY")
SILICONFLOW_BASE_URL = "https://api.siliconflow.cn/v1"
EMBED_MODEL_NAME = "BAAI/bge-m3"
RERANK_MODEL_NAME = "BAAI/bge-reranker-v2-m3"

LONGMAO_API_KEY = get_env_flexible("LONGMAO_API_KEY")
LONGMAO_BASE_URL = get_env_flexible("LONGMAO_BASE_URL")
LONGMAO_MODEL = get_env_flexible("LONGMAO_MODEL", "LongCat-Flash-Chat")

# è®¾ç½®å…¨å±€ LlamaIndex é…ç½®
Settings.embed_model = SiliconFlowEmbedding(
    model_name=EMBED_MODEL_NAME,
    api_key=SILICONFLOW_API_KEY,
    api_base=SILICONFLOW_BASE_URL,
)
Settings.embed_batch_size = 20
Settings.llm = OpenAILike(
    model=LONGMAO_MODEL,
    api_key=LONGMAO_API_KEY,
    api_base=LONGMAO_BASE_URL,
    temperature=0.1,
    is_chat_model=True,
)

# ================= æ•°æ®åº“æ“ä½œ =================
def get_db_config():
    """ä»ç¯å¢ƒå˜é‡ã€æ³¨å†Œè¡¨æˆ– secrets.json è·å–æ•°æ®åº“é…ç½®"""
    return {
        "dbname": get_env_flexible("DB_NAME", "media_knowledge_base"),
        "user": get_env_flexible("DB_USER", "root"),
        "password": get_env_flexible("DB_PASSWORD", "15671040800q"),
        "host": get_env_flexible("DB_HOST", "127.0.0.1"),
        "port": get_env_flexible("DB_PORT", "5433")
    }

async def search_kb(query_str: str, up_mid: Optional[int] = None, 
                   use_query_engine: bool = True, top_k: int = 5):
    """
    åœ¨ B ç«™çŸ¥è¯†åº“ä¸­è¿›è¡Œè¯­ä¹‰æ£€ç´¢
    """
    config = get_db_config()
    
    # 1. åˆå§‹åŒ–å‘é‡å­˜å‚¨è¿æ¥
    vector_store = PGVectorStore.from_params(
        host=config["host"],
        port=config["port"],
        database=config["dbname"],
        user=config["user"],
        password=config["password"],
        table_name="llama_collection",
        embed_dim=1024,
        perform_setup=False,
        hybrid_search=True,
    )
    
    # 2. åŠ è½½ç´¢å¼•
    storage_context = StorageContext.from_defaults(vector_store=vector_store)
    index = VectorStoreIndex.from_vector_store(vector_store, storage_context=storage_context)
    
    # 3. åˆ›å»ºé‡æ’å™¨
    reranker = SiliconFlowRerank(
        model=RERANK_MODEL_NAME,
        api_key=SILICONFLOW_API_KEY,
        top_n=top_k
    )
    
    # 4. é…ç½®å…ƒæ•°æ®è¿‡æ»¤
    filters = None
    if up_mid:
        filters = MetadataFilters(
            filters=[ExactMatchFilter(key="up_mid", value=up_mid)]
        )
        console.print(f"[cyan]ğŸ” åªæœç´¢ UP ä¸» {up_mid} çš„è§†é¢‘[/cyan]")
    
    if use_query_engine:
        query_engine = index.as_query_engine(
            similarity_top_k=20,
            node_postprocessors=[reranker],
            response_mode=ResponseMode.COMPACT,
            filters=filters,
            vector_store_query_mode=VectorStoreQueryMode.HYBRID,
        )
        
        console.print(f"[bold green]ğŸ” æ­£åœ¨æŸ¥è¯¢:[/bold green] {query_str}")
        response = await query_engine.aquery(query_str)
        
        # ä½¿ç”¨ rich è¾“å‡ºç»“æœ
        console.print(Panel(Markdown(response.response), title="ğŸ¤– AI ç”Ÿæˆçš„ç­”æ¡ˆ", border_style="green"))
        
        table = Table(title=f"ğŸ“„ ç›¸å…³æºæ–‡æ¡£ ({len(response.source_nodes)} æ¡)")
        table.add_column("Index", style="dim")
        table.add_column("Title", style="cyan")
        table.add_column("BVID", style="magenta")
        table.add_column("Score", style="yellow")
        
        for i, node in enumerate(response.source_nodes, 1):
            metadata = node.metadata
            table.add_row(
                str(i),
                metadata.get('title', 'Unknown'),
                metadata.get('bvid', 'N/A'),
                f"{node.score:.4f}"
            )
        
        console.print(table)
        
        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        try:
            with open("search_context.tmp", "w", encoding="utf-8") as f:
                f.write("<KNOWLEDGE_BASE_START>\n")
                f.write(f"QUERY: {query_str}\n")
                f.write(f"ANSWER: {response.response}\n\n")
                f.write("SOURCES:\n")
                for node in response.source_nodes:
                    metadata = node.metadata
                    f.write(f"TITLE: {metadata.get('title')}\n")
                    f.write(f"BVID: {metadata.get('bvid')}\n")
                    f.write(f"SCORE: {node.score:.4f}\n")
                    f.write(f"CONTENT: {node.get_content()}\n")
                    f.write("---CHUNK_END---\n")
                f.write("<KNOWLEDGE_BASE_END>\n")
        except Exception as e:
            console.print(f"[red]âš ï¸ å†™å…¥ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}[/red]")
            
    else:
        retriever = index.as_retriever(
            similarity_top_k=20,
            vector_store_query_mode=VectorStoreQueryMode.HYBRID,
            alpha=0.3,
            filters=filters,
        )
        
        console.print(f"[bold green]ğŸ” æ­£åœ¨æ£€ç´¢:[/bold green] {query_str}")
        nodes = await retriever.aretrieve(query_str)
        reranked_nodes = reranker.postprocess_nodes(nodes, query_bundle=QueryBundle(query_str))
        
        table = Table(title=f"ğŸ“„ æ£€ç´¢ç»“æœ ({len(reranked_nodes)} æ¡)")
        table.add_column("Index", style="dim")
        table.add_column("Title", style="cyan")
        table.add_column("BVID", style="magenta")
        table.add_column("Score", style="yellow")
        
        for i, node in enumerate(reranked_nodes, 1):
            metadata = node.node.metadata
            table.add_row(
                str(i),
                metadata.get('title', 'Unknown'),
                metadata.get('bvid', 'N/A'),
                f"{node.score:.4f}"
            )
        
        console.print(table)
        
        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        try:
            with open("search_context.tmp", "w", encoding="utf-8") as f:
                f.write("<KNOWLEDGE_BASE_START>\n")
                for node in reranked_nodes:
                    metadata = node.node.metadata
                    f.write(f"TITLE: {metadata.get('title')}\n")
                    f.write(f"BVID: {metadata.get('bvid')}\n")
                    f.write(f"SCORE: {node.score:.4f}\n")
                    f.write(f"CONTENT: {node.node.get_content()}\n")
                    f.write("---CHUNK_END---\n")
                f.write("<KNOWLEDGE_BASE_END>\n")
        except Exception as e:
            print(f"âš ï¸ å†™å…¥ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Bç«™è§†é¢‘çŸ¥è¯†åº“è¯­ä¹‰æ£€ç´¢å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬æœç´¢ï¼ˆç”Ÿæˆç­”æ¡ˆï¼‰
  python bili_search_llama.py "DeepSeekå¦‚ä½•ä½¿ç”¨"
  
  # åªè¿”å›åŸå§‹åˆ†ç‰‡ï¼ˆä¸ç”Ÿæˆç­”æ¡ˆï¼‰
  python bili_search_llama.py "æœ¬åœ°éƒ¨ç½²RAG" --raw
  
  # æŒ‡å®š UP ä¸»æœç´¢
  python bili_search_llama.py "AIåº”ç”¨" --up 3546830417693175
  
  # è°ƒæ•´è¿”å›æ•°é‡
  python bili_search_llama.py "Python RAG" --top-k 10
        """
    )
    
    parser.add_argument("query", nargs="+", help="æœç´¢æŸ¥è¯¢")
    parser.add_argument("--up", type=int, metavar="UID", help="åªæœç´¢æŒ‡å®š UP ä¸»çš„è§†é¢‘")
    parser.add_argument("--raw", action="store_true", help="åªè¿”å›åŸå§‹åˆ†ç‰‡ï¼Œä¸ç”Ÿæˆç­”æ¡ˆ")
    parser.add_argument("--top-k", type=int, default=5, help="è¿”å›ç»“æœæ•°é‡ï¼ˆé»˜è®¤ 5ï¼‰")
    
    args = parser.parse_args()
    query = " ".join(args.query)
    
    asyncio.run(search_kb(
        query_str=query,
        up_mid=args.up,
        use_query_engine=not args.raw,
        top_k=args.top_k
    ))
